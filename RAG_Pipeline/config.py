HF_TOKEN = ''
MODEL_NAME = 'meta-llama/Llama-2-7b-chat-hf'

# generation_config.max_new_tokens = 1024
# generation_config.temperature = 0.0001
# generation_config.top_p = 0.95
# generation_config.do_sample = True
# generation_config.repetition_penalty = 1.15